{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmANPR2jhCR6"
      },
      "source": [
        "# Simple Object Detection in Tensorflow\n",
        "\n",
        "This lab will walk you through how to use object detection models available in [Tensorflow Hub](https://www.tensorflow.org/hub). In the following sections, you will:\n",
        "\n",
        "* explore the Tensorflow Hub for object detection models\n",
        "* load the models in your workspace\n",
        "* preprocess an image for inference\n",
        "* run inference on the models and inspect the output\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DkMLuGDhCR6"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OEoRKdmByrb0"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "import tempfile\n",
        "from six.moves.urllib.request import urlopen\n",
        "from six import BytesIO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb8MBgTOhCR6"
      },
      "source": [
        "### Download the model from Tensorflow Hub\n",
        "\n",
        "Tensorflow Hub is a repository of trained machine learning models which you can reuse in your own projects.\n",
        "- You can see the domains covered [here](https://tfhub.dev/) and its subcategories.\n",
        "- For this lab, you will want to look at the [image object detection subcategory](https://tfhub.dev/s?module-type=image-object-detection).\n",
        "- You can select a model to see more information about it and copy the URL so you can download it to your workspace.\n",
        "- We selected a [inception resnet version 2](https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1)\n",
        "- You can also modify this following cell to choose the other model that we selected, [ssd mobilenet version 2](https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C9pCzz4uy20U"
      },
      "outputs": [],
      "source": [
        "# you can switch the commented lines here to pick the other model\n",
        "\n",
        "# inception resnet version 2\n",
        "module_handle = \"https://tfhub.dev/google/faster_rcnn/openimages_v4/inception_resnet_v2/1\"\n",
        "\n",
        "# You can choose ssd mobilenet version 2 instead and compare the results\n",
        "#module_handle = \"https://tfhub.dev/google/openimages_v4/ssd/mobilenet_v2/1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3trj5FbhCR6"
      },
      "source": [
        "#### Load the model\n",
        "\n",
        "Next, you'll load the model specified by the `module_handle`.\n",
        "- This will take a few minutes to load the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0WHkGDHfhCR6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "2024-02-17 02:03:02.333119: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
          ]
        }
      ],
      "source": [
        "model = hub.load(module_handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ey0FpHGhCR6"
      },
      "source": [
        "#### Choose the default signature\n",
        "\n",
        "Some models in the Tensorflow hub can be used for different tasks. So each model's documentation should show what *signature* to use when running the model.\n",
        "- If you want to see if a model has more than one signature then you can do something like `print(hub.load(module_handle).signatures.keys())`. In your case, the models you will be using only have the `default` signature so you don't have to worry about other types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "X1BU7AGthCR6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KeysView(_SignatureMap({'default': <ConcreteFunction pruned(images) at 0x2DE26FE50>}))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# take a look at the available signatures for this particular model\n",
        "model.signatures.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfc9ax9hhCR6"
      },
      "source": [
        "Please choose the 'default' signature for your object detector.\n",
        "- For object detection models, its 'default' signature will accept a batch of image tensors and output a dictionary describing the objects detected, which is what you'll want here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pzwR5zE_hCR7"
      },
      "outputs": [],
      "source": [
        "detector = model.signatures['default']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wvb-3r3thCR7"
      },
      "source": [
        "### download_and_resize_image\n",
        "\n",
        "This function downloads an image specified by a given \"url\", pre-processes it, and then saves it to disk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ucsxak_qhCR7"
      },
      "outputs": [],
      "source": [
        "def download_and_resize_image(url, new_width=256, new_height=256):\n",
        "    '''\n",
        "    Fetches an image online, resizes it and saves it locally.\n",
        "\n",
        "    Args:\n",
        "        url (string) -- link to the image\n",
        "        new_width (int) -- size in pixels used for resizing the width of the image\n",
        "        new_height (int) -- size in pixels used for resizing the length of the image\n",
        "\n",
        "    Returns:\n",
        "        (string) -- path to the saved image\n",
        "    '''\n",
        "\n",
        "\n",
        "    # create a temporary file ending with \".jpg\"\n",
        "    _, filename = tempfile.mkstemp(suffix=\".jpg\")\n",
        "\n",
        "    # opens the given URL\n",
        "    response = urlopen(url)\n",
        "\n",
        "    # reads the image fetched from the URL\n",
        "    image_data = response.read()\n",
        "\n",
        "    # puts the image data in memory buffer\n",
        "    image_data = BytesIO(image_data)\n",
        "\n",
        "    # opens the image\n",
        "    pil_image = Image.open(image_data)\n",
        "\n",
        "    # resizes the image. will crop if aspect ratio is different.\n",
        "    pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n",
        "\n",
        "    # converts to the RGB colorspace\n",
        "    pil_image_rgb = pil_image.convert(\"RGB\")\n",
        "\n",
        "    # saves the image to the temporary file created earlier\n",
        "    pil_image_rgb.save(filename, format=\"JPEG\", quality=90)\n",
        "\n",
        "    print(\"Image downloaded to %s.\" % filename)\n",
        "\n",
        "    return filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "def resize_image(jpeg_image, new_width=256, new_height=256):\n",
        "    '''\n",
        "    Resizes an image and converts it to a tensor.\n",
        "\n",
        "    Args:\n",
        "        image_path (string) -- path to an image\n",
        "\n",
        "    Returns:\n",
        "        (tensor) -- the resized image\n",
        "    '''\n",
        "\n",
        "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
        "    img = tf.image.convert_image_dtype(jpeg_image, tf.float32)\n",
        "\n",
        "    # resize the image to the desired size.\n",
        "    img = tf.image.resize(img, [new_width, new_height])\n",
        "    return img\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7qodEJHhCR7"
      },
      "source": [
        "### Download and preprocess an image\n",
        "\n",
        "Now, using `download_and_resize_image` you can get a sample image online and save it locally.\n",
        "- We've provided a URL for you, but feel free to choose another image to run through the object detector.\n",
        "- You can use the original width and height of the image but feel free to modify it and see what results you get."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xHTDalVrhCR7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/0h/kf11cdt562d74pkdycbwbbnm0000gn/T/ipykernel_46720/546765189.py:31: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
            "  pil_image = ImageOps.fit(pil_image, (new_width, new_height), Image.ANTIALIAS)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image downloaded to /var/folders/0h/kf11cdt562d74pkdycbwbbnm0000gn/T/tmpq32sydsk.jpg.\n"
          ]
        }
      ],
      "source": [
        "# You can choose a different URL that points to an image of your choice\n",
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/f/fb/20130807_dublin014.JPG\"\n",
        "\n",
        "# download the image and use the original height and width\n",
        "downloaded_image_path = download_and_resize_image(image_url, 3872, 2592)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVNXUKMIhCR7"
      },
      "source": [
        "### run_detector\n",
        "\n",
        "This function will take in the object detection model `detector` and the path to a sample image, then use this model to detect objects and display its predicted class categories and detection boxes.\n",
        "- run_detector uses `load_image` to convert the image into a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "wkkiQzKlhCR7"
      },
      "outputs": [],
      "source": [
        "def load_img(path):\n",
        "    '''\n",
        "    Loads a JPEG image and converts it to a tensor.\n",
        "\n",
        "    Args:\n",
        "        path (string) -- path to a locally saved JPEG image\n",
        "\n",
        "    Returns:\n",
        "        (tensor) -- an image tensor\n",
        "    '''\n",
        "\n",
        "    # read the file\n",
        "    img = tf.io.read_file(path)\n",
        "\n",
        "    # convert to a tensor\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "\n",
        "    return img\n",
        "\n",
        "def load_img_with_resize(path):\n",
        "    '''\n",
        "    Loads a JPEG image and converts it to a tensor.\n",
        "\n",
        "    Args:\n",
        "        path (string) -- path to a locally saved JPEG image\n",
        "\n",
        "    Returns:\n",
        "        (tensor) -- an image tensor\n",
        "    '''\n",
        "\n",
        "    # read the file\n",
        "    img = tf.io.read_file(path)\n",
        "\n",
        "    # convert to a tensor\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "\n",
        "    img = resize_image(img)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def run_detector(detector, path):\n",
        "    '''\n",
        "    Runs inference on a local file using an object detection model.\n",
        "\n",
        "    Args:\n",
        "        detector (model) -- an object detection model loaded from TF Hub\n",
        "        path (string) -- path to an image saved locally\n",
        "    '''\n",
        "\n",
        "    # load an image tensor from a local file path\n",
        "    img = load_img_with_resize(path)\n",
        "\n",
        "    # add a batch dimension in front of the tensor\n",
        "    converted_img  = tf.image.convert_image_dtype(img, tf.float32)[tf.newaxis, ...]\n",
        "\n",
        "    # run inference using the model\n",
        "    result = detector(converted_img)\n",
        "\n",
        "    # save the results in a dictionary\n",
        "    result = {key:value.numpy() for key,value in result.items()}\n",
        "\n",
        "    # print results\n",
        "    print(\"Found %d objects.\" % len(result[\"detection_scores\"]))\n",
        "\n",
        "    print(result[\"detection_scores\"])\n",
        "    print(result[\"detection_class_entities\"])\n",
        "    print(result[\"detection_boxes\"])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSEeJSkxhCR7"
      },
      "source": [
        "### Run inference on the image\n",
        "\n",
        "You can run your detector by calling the `run_detector` function. This will print the number of objects found followed by three lists:\n",
        "\n",
        "* The detection scores of each object found (i.e. how confident the model is),\n",
        "* The classes of each object found,\n",
        "* The bounding boxes of each object\n",
        "\n",
        "You will see how to overlay this information on the original image in the next sections and in this week's assignment!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "csanHvDIz4_t"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 100 objects.\n",
            "[0.58689654 0.5608543  0.5317218  0.45770994 0.4273932  0.42051673\n",
            " 0.40685555 0.3808453  0.25275797 0.25275356 0.15794174 0.13544498\n",
            " 0.10365563 0.09164076 0.08353359 0.0705786  0.06510404 0.06073282\n",
            " 0.05605806 0.05464158 0.05229337 0.0514489  0.05016447 0.05002847\n",
            " 0.04638358 0.04526342 0.03601967 0.03576326 0.0335372  0.03261468\n",
            " 0.03125096 0.02637507 0.02562196 0.02488858 0.02437097 0.02365883\n",
            " 0.02227049 0.01990807 0.01808504 0.01770908 0.01594985 0.01435061\n",
            " 0.01240178 0.01230611 0.01205754 0.01132088 0.01068268 0.01003302\n",
            " 0.00941504 0.00926068 0.00911617 0.0090998  0.00900297 0.00898716\n",
            " 0.00886944 0.00876196 0.00861757 0.00842155 0.00826626 0.00821178\n",
            " 0.00815838 0.00787643 0.00781133 0.00777231 0.00734727 0.00731079\n",
            " 0.00705872 0.00648709 0.00643287 0.00631288 0.00628432 0.00612455\n",
            " 0.00603614 0.00601578 0.00599423 0.00596808 0.00546325 0.00511225\n",
            " 0.00503788 0.00455137 0.00453315 0.00445947 0.00438213 0.00435852\n",
            " 0.00423351 0.00411374 0.00409124 0.00408394 0.00392205 0.00380625\n",
            " 0.00379423 0.00376329 0.00375957 0.00372438 0.0036538  0.00362685\n",
            " 0.00361258 0.00350587 0.00349758 0.00324443]\n",
            "[b'Window' b'Window' b'Building' b'Building' b'Window' b'Building'\n",
            " b'Window' b'Window' b'Book' b'Window' b'Building' b'Building' b'Building'\n",
            " b'House' b'Window' b'Building' b'Shelf' b'Bookcase' b'Shelf'\n",
            " b'Picture frame' b'Building' b'Skyscraper' b'Street light' b'Bookcase'\n",
            " b'Building' b'Skyscraper' b'Window' b'Window' b'Building' b'Building'\n",
            " b'House' b'Wheel' b'Window' b'Billboard' b'Window' b'Billboard'\n",
            " b'Building' b'Window' b'Building' b'Window' b'Building' b'Picture frame'\n",
            " b'Poster' b'Window' b'Book' b'Book' b'Book' b'Furniture' b'House'\n",
            " b'Window' b'Door' b'Street light' b'Skyscraper' b'Skyscraper' b'Poster'\n",
            " b'Window' b'Building' b'Window' b'Skyscraper' b'House' b'Poster' b'Wheel'\n",
            " b'Poster' b'Skyscraper' b'Building' b'House' b'Window' b'Window blind'\n",
            " b'Window' b'Window' b'Curtain' b'Window' b'Tower' b'Shelf' b'Wheel'\n",
            " b'Furniture' b'Window' b'Tower' b'Skyscraper' b'Auto part'\n",
            " b'Street light' b'Bookcase' b'Tire' b'Skyscraper' b'Window' b'House'\n",
            " b'Clothing' b'Poster' b'House' b'House' b'Street light' b'Book' b'Door'\n",
            " b'Mirror' b'Skyscraper' b'House' b'Curtain' b'House' b'Shelf'\n",
            " b'Furniture']\n",
            "[[0.00000000e+00 4.07722980e-01 5.12339413e-01 7.22846568e-01]\n",
            " [6.55635118e-01 2.73013443e-01 9.81025636e-01 5.79132378e-01]\n",
            " [0.00000000e+00 1.98478196e-02 1.00000000e+00 9.89939511e-01]\n",
            " [0.00000000e+00 6.94622636e-01 9.97923017e-01 9.84399557e-01]\n",
            " [4.97299731e-02 6.65107742e-02 7.95890689e-01 7.87491858e-01]\n",
            " [2.29802448e-03 4.24807370e-01 1.00000000e+00 9.67214286e-01]\n",
            " [0.00000000e+00 1.09890647e-01 5.23066103e-01 5.59319913e-01]\n",
            " [3.35371657e-03 8.01865682e-02 3.80871892e-01 4.59156662e-01]\n",
            " [6.00824177e-01 5.66328466e-01 9.34534609e-01 7.37523496e-01]\n",
            " [3.55748506e-03 2.09683582e-01 5.52742541e-01 8.04231346e-01]\n",
            " [5.26159704e-01 5.61062619e-02 1.00000000e+00 9.51174617e-01]\n",
            " [0.00000000e+00 6.08997121e-02 5.72200954e-01 9.39755857e-01]\n",
            " [1.73072010e-01 8.30648184e-01 1.00000000e+00 9.95352387e-01]\n",
            " [0.00000000e+00 1.21146142e-02 1.00000000e+00 1.00000000e+00]\n",
            " [8.42683204e-03 2.49253139e-01 3.38095546e-01 4.28218961e-01]\n",
            " [1.95120368e-02 8.34103301e-02 3.74839425e-01 4.45250362e-01]\n",
            " [5.43517292e-01 5.65035880e-01 1.00000000e+00 8.63933504e-01]\n",
            " [5.58437586e-01 5.64096570e-01 9.96301889e-01 7.52298176e-01]\n",
            " [5.52811325e-01 5.46178997e-01 9.71532822e-01 7.64300466e-01]\n",
            " [4.99666855e-03 4.00533140e-01 5.21976411e-01 7.56769300e-01]\n",
            " [1.03614805e-03 2.06012189e-01 7.66667724e-01 8.63271296e-01]\n",
            " [0.00000000e+00 3.91903341e-01 5.58110356e-01 7.38936961e-01]\n",
            " [1.78321078e-01 8.36020410e-01 9.58465993e-01 9.92024660e-01]\n",
            " [5.32793999e-01 5.54021716e-01 1.00000000e+00 8.72871816e-01]\n",
            " [1.03100203e-02 1.10193506e-01 4.17188376e-01 6.43684626e-01]\n",
            " [6.80821773e-04 7.48068616e-02 3.58283490e-01 2.65825808e-01]\n",
            " [3.85028809e-01 7.35008791e-02 9.44337904e-01 9.14522707e-01]\n",
            " [9.41983517e-03 1.14619918e-01 3.39531183e-01 3.13606530e-01]\n",
            " [0.00000000e+00 3.89411211e-01 5.43471515e-01 7.50075221e-01]\n",
            " [1.17788194e-02 8.37315619e-02 3.55109960e-01 2.70672888e-01]\n",
            " [0.00000000e+00 7.99001813e-01 1.00000000e+00 9.96600270e-01]\n",
            " [3.12065065e-01 8.50143194e-01 5.11222780e-01 9.61970210e-01]\n",
            " [1.33063212e-01 7.83070922e-01 3.25923473e-01 8.47822070e-01]\n",
            " [5.25010228e-01 7.35388041e-01 9.67180789e-01 8.94940495e-01]\n",
            " [6.44830102e-03 9.20860395e-02 3.32681894e-01 2.50460863e-01]\n",
            " [4.55734273e-03 4.03459340e-01 5.36354363e-01 7.06632257e-01]\n",
            " [6.79183006e-01 2.96587467e-01 9.83582556e-01 5.75406373e-01]\n",
            " [8.18068460e-02 2.69450486e-01 9.35619950e-01 9.09871757e-01]\n",
            " [3.51620972e-01 8.85070801e-01 9.97228742e-01 9.97922361e-01]\n",
            " [1.23504009e-02 5.44159889e-01 3.44276071e-01 6.89370155e-01]\n",
            " [4.74363327e-01 7.22604454e-01 9.99517977e-01 9.27903652e-01]\n",
            " [5.72407126e-01 7.19008565e-01 9.70727444e-01 9.17125762e-01]\n",
            " [5.53376138e-01 6.70849800e-01 9.67349589e-01 9.10562336e-01]\n",
            " [1.12397082e-01 9.07450557e-01 2.70848840e-01 9.35350180e-01]\n",
            " [5.94794869e-01 5.67600369e-01 9.67476904e-01 8.23113978e-01]\n",
            " [7.53621431e-03 3.86104941e-01 5.06716073e-01 7.27988303e-01]\n",
            " [8.12852290e-03 3.89421970e-01 3.99325252e-01 4.82823342e-01]\n",
            " [5.58835864e-01 5.44766128e-01 1.00000000e+00 8.64196777e-01]\n",
            " [0.00000000e+00 2.94954441e-02 5.58563828e-01 9.17042136e-01]\n",
            " [4.64795437e-03 5.61249673e-01 2.33929500e-01 6.24993265e-01]\n",
            " [0.00000000e+00 2.58836120e-01 3.38707894e-01 4.20655936e-01]\n",
            " [4.73502092e-02 7.75644958e-01 9.24617767e-01 9.81960654e-01]\n",
            " [0.00000000e+00 8.19336414e-01 9.83127058e-01 9.97432351e-01]\n",
            " [4.08641584e-02 2.42022961e-01 9.30346608e-01 8.99875700e-01]\n",
            " [6.02400184e-01 5.72879732e-01 9.47632194e-01 7.45938361e-01]\n",
            " [5.55952430e-01 7.17424095e-01 9.62042153e-01 9.12620068e-01]\n",
            " [6.43949807e-01 2.24109560e-01 9.96443927e-01 6.35511875e-01]\n",
            " [1.33079533e-02 7.21693277e-01 1.94180116e-01 7.81629682e-01]\n",
            " [5.04327595e-01 7.22478151e-01 9.90810394e-01 9.19665754e-01]\n",
            " [2.64869705e-02 4.18075770e-01 1.00000000e+00 9.77169037e-01]\n",
            " [1.60756689e-02 3.89843136e-01 5.15233994e-01 7.41008699e-01]\n",
            " [1.29567772e-01 7.74334490e-01 3.61148030e-01 8.44389200e-01]\n",
            " [5.88011563e-01 7.27536500e-01 9.53915656e-01 8.88519824e-01]\n",
            " [0.00000000e+00 5.77596314e-02 3.76054198e-01 4.52192307e-01]\n",
            " [5.26708603e-01 5.95537841e-01 1.00000000e+00 9.34473515e-01]\n",
            " [5.09554327e-01 4.62881476e-02 9.96640861e-01 9.21409845e-01]\n",
            " [1.93868007e-03 6.97152138e-01 2.93967009e-01 7.99516022e-01]\n",
            " [3.91064957e-02 1.25556156e-01 8.44994247e-01 7.43370473e-01]\n",
            " [1.08886724e-02 7.37660468e-01 1.64696857e-01 7.87471890e-01]\n",
            " [9.23734065e-03 7.07687140e-01 2.67866969e-01 7.66324818e-01]\n",
            " [1.01181038e-03 2.42565513e-01 3.37390363e-01 4.28376168e-01]\n",
            " [8.77783448e-03 5.62444687e-01 2.15891421e-01 5.91348588e-01]\n",
            " [0.00000000e+00 8.11574087e-02 3.65787923e-01 2.66876310e-01]\n",
            " [2.50418842e-01 2.22152129e-01 9.86102700e-01 9.48846757e-01]\n",
            " [9.21211362e-01 9.02822196e-01 9.97199535e-01 9.60527062e-01]\n",
            " [5.83605230e-01 5.60432076e-01 9.80662644e-01 7.57267535e-01]\n",
            " [1.21383509e-02 7.41516531e-01 9.88251269e-02 7.86673605e-01]\n",
            " [1.34472661e-02 8.28208268e-01 9.64589894e-01 9.96561289e-01]\n",
            " [2.92147323e-02 5.42743742e-01 9.70800221e-01 9.46898818e-01]\n",
            " [3.07983875e-01 8.31902385e-01 5.15382886e-01 9.77196395e-01]\n",
            " [3.84664744e-01 8.90512288e-01 9.74456787e-01 9.97311652e-01]\n",
            " [2.23540038e-01 1.58543915e-01 9.48855996e-01 1.00000000e+00]\n",
            " [1.42151445e-01 7.80611396e-01 3.31713319e-01 8.49163115e-01]\n",
            " [7.22211204e-04 6.84463754e-02 3.53739381e-01 1.55908108e-01]\n",
            " [4.54164028e-01 2.97054589e-01 9.70962226e-01 9.49886918e-01]\n",
            " [0.00000000e+00 1.95397094e-01 8.03021550e-01 8.75191689e-01]\n",
            " [6.24510527e-01 5.80191672e-01 9.51786935e-01 7.31551051e-01]\n",
            " [5.81046224e-01 5.65703630e-01 9.88629401e-01 8.64204824e-01]\n",
            " [2.17500310e-02 8.89977515e-01 6.19763970e-01 9.91043627e-01]\n",
            " [1.96940064e-01 8.41965199e-01 1.00000000e+00 9.89338815e-01]\n",
            " [2.05191039e-02 7.13170707e-01 7.81503201e-01 9.36472714e-01]\n",
            " [5.66842198e-01 6.95335329e-01 9.75937426e-01 9.09821212e-01]\n",
            " [5.88313304e-02 8.28714013e-01 9.64948952e-01 9.75434363e-01]\n",
            " [3.16917188e-02 3.93676788e-01 4.66898710e-01 7.61243284e-01]\n",
            " [5.23407012e-03 9.52931717e-02 5.11100054e-01 7.63550758e-01]\n",
            " [0.00000000e+00 6.64665774e-02 3.97357941e-01 4.59175020e-01]\n",
            " [0.00000000e+00 4.33444440e-01 5.33262312e-01 7.34348059e-01]\n",
            " [3.76782656e-01 8.82842541e-01 1.00000000e+00 9.98064876e-01]\n",
            " [5.60043931e-01 6.89455092e-01 1.00000000e+00 9.20853198e-01]\n",
            " [5.38801491e-01 7.04431176e-01 1.00000000e+00 9.23225641e-01]]\n"
          ]
        }
      ],
      "source": [
        "# runs the object detection model and prints information about the objects found\n",
        "image_path = 'test-images/test.jpg'\n",
        "run_detector(detector, image_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
